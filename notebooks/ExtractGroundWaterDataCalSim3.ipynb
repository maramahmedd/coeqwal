{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45f814080c0b939",
   "metadata": {},
   "source": [
    "## Switches and flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82e6c6-8783-4c8c-8094-b612c260543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtractIndividualStudies = True\n",
    "ExtractGroupedStudies = True\n",
    "AggregateStorageLevels = True\n",
    "NumSrVars = 66\n",
    "ConvertAcFtToTaf = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a9bc43-c6c3-4103-a45d-55b7a2938c13",
   "metadata": {},
   "source": [
    "## Import standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c91bd1a1e8beca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T08:04:38.276992Z",
     "start_time": "2024-07-20T08:04:38.274280Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# append coeqwal packages to path\n",
    "sys.path.append('./coeqwalpackage')\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cqwlutils as cu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9145a-2421-4dd1-a31d-1edb2b5a4f64",
   "metadata": {},
   "source": [
    "## Import custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61561cb3284fbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T20:35:57.550559300Z",
     "start_time": "2024-03-07T20:35:57.462942100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import custom modules - NEED WINDOWS OS (NOTE: I had to run this twice, must check why this happens!)\n",
    "from coeqwalpackage.DataExtraction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a886dad8c6c902",
   "metadata": {},
   "source": [
    "## Define contol file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0f49b-17c9-40f5-8861-5680673a5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "CtrlFile = 'CalSim3GroundWaterDataExtractionInitFile_v1.xlsx'\n",
    "CtrlTab = 'Init'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0070e30e-fec8-4e22-bf9f-bd43e1d4f7a9",
   "metadata": {},
   "source": [
    "## Read from control file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614d95e-3b73-42f9-a330-7750b45b921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ScenarioListFile, ScenarioListTab, ScenarioListPath, GW1DssNamesOutPath, GW2DssNamesOutPath, ScenarioIndicesOutPath, DssDirsOutPath, VarListPath, VarListFile, VarListTab, VarOutPath, DataOutPath, ConvertDataOutPath, ExtractionSubPath, DemandDeliverySubPath, ModelSubPath, GroupDataDirPath, ScenarioDir, GW1DssMin, GW1DssMax, GW2DssMin, GW2DssMax, NameMin, NameMax, DirMin, DirMax, IndexMin, IndexMax, StartMin, StartMax, EndMin, EndMax, VarMin, VarMax, DemandFilePath, DemandFileName, DemandFileTab, DemMin, DemMax, InflowOutSubPath, InflowFilePath, InflowFileName, InflowFileTab, InflowMin, InflowMax = cu.read_init_file(CtrlFile, CtrlTab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2529c38-c663-43ee-811d-415fdd815743",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([ScenarioListFile, ScenarioListTab, ScenarioListPath, GW1DssNamesOutPath, GW2DssNamesOutPath, ScenarioIndicesOutPath, DssDirsOutPath, VarListPath, VarListFile, VarListTab, VarOutPath, DataOutPath, ConvertDataOutPath, ExtractionSubPath, DemandDeliverySubPath, ModelSubPath, GroupDataDirPath, ScenarioDir, GW1DssMin, GW1DssMax, GW2DssMin, GW2DssMax, NameMin, NameMax, DirMin, DirMax, IndexMin, IndexMax, StartMin, StartMax, EndMin, EndMax, VarMin, VarMax, DemandFilePath, DemandFileName, DemandFileTab, DemMin, DemMax, InflowOutSubPath, InflowFilePath, InflowFileName, InflowFileTab, InflowMin, InflowMax])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd54452-9c03-4f71-ba08-06fe3b8ba071",
   "metadata": {},
   "source": [
    "## Check for output directory and create if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168bb493-d379-4c25-a56e-e3da4fab4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if output directory exists\n",
    "if not os.path.exists(GroupDataDirPath):\n",
    "    # print warning\n",
    "    print(\"Warning: directory \" + GroupDataDirPath + \" does not exists and will be created\")\n",
    "    \n",
    "    # Create the directory\n",
    "    os.makedirs(GroupDataDirPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f736a-622a-4ca0-86f7-8979963700bf",
   "metadata": {},
   "source": [
    "## Define Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17492ae9-5a01-4eb2-b6e1-4422fbd39d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values as defined by CalSim3\n",
    "Nan1 = -901\n",
    "Nan2 = -902"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cf686-69bd-4a22-bc35-42769740aae7",
   "metadata": {},
   "source": [
    "## Read indeces, dss names, directory names, start and end dates, time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2a998-acab-49e7-a2bd-25e6336f0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw1dsshdr, gw1dssname = cu.read_from_excel(ScenarioListPath, ScenarioListTab, GW1DssMin, GW1DssMax, hdr=True)\n",
    "gw1dss_names = []\n",
    "for i in range(len(gw1dssname)):\n",
    "    gw1dss_names.append(gw1dssname[i][0])\n",
    "gw1dss_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511228c-0d07-4308-86e7-bc1f9a3f74a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw2dsshdr, gw2dssname = cu.read_from_excel(ScenarioListPath, ScenarioListTab, GW2DssMin, GW2DssMax, hdr=True)\n",
    "gw2dss_names = []\n",
    "for i in range(len(gw2dssname)):\n",
    "    gw2dss_names.append(gw2dssname[i][0])\n",
    "gw2dss_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903558b7-1a87-4911-ba9a-2f7ac847da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexhdr, index_name = cu.read_from_excel(ScenarioListPath, ScenarioListTab, IndexMin, IndexMax, hdr=True)\n",
    "index_names = []\n",
    "for i in range(len(index_name)):\n",
    "    index_names.append(index_name[i][0])\n",
    "index_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c26379-84b3-425a-a65e-2b6e6852e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyhdr, study_name = cu.read_from_excel(ScenarioListPath, ScenarioListTab, NameMin, NameMax, hdr=True)\n",
    "study_names = []\n",
    "for i in range(len(study_name)):\n",
    "    study_names.append(study_name[i][0])\n",
    "study_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0c016-d82e-4927-b944-f09db7b2f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirhdr, dir_name = cu.read_from_excel(ScenarioListPath, ScenarioListTab, DirMin, DirMax, hdr=True)\n",
    "dir_names = []\n",
    "for i in range(len(dir_name)):\n",
    "    dir_names.append(dir_name[i][0])\n",
    "dir_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456c0e6-61d8-427b-8d45-1814053c4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "starthdr, start_date = cu.read_from_excel(ScenarioListPath, ScenarioListTab, StartMin, StartMax, hdr=True)\n",
    "start_dates = []\n",
    "for i in range(len(start_date)):\n",
    "    start_dates.append(start_date[i][0])\n",
    "datetime_start_dates = pd.to_datetime(start_dates)\n",
    "# turns out that dss reading library wands a dt datetime, not pd datetime\n",
    "dt_datetime_start_dates = [dt.to_pydatetime() for dt in datetime_start_dates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a887b-829e-4773-bb8c-60e8d6ff35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "endhdr, end_date = cu.read_from_excel(ScenarioListPath, ScenarioListTab, EndMin, EndMax, hdr=True)\n",
    "end_dates = []\n",
    "for i in range(len(end_date)):\n",
    "    end_dates.append(end_date[i][0])\n",
    "# turns out that dss reading library wands a dt datetime, not pd datetime\n",
    "datetime_end_dates = pd.to_datetime(end_dates)\n",
    "dt_datetime_end_dates = [dt.to_pydatetime() for dt in datetime_end_dates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b72d5a-0f63-4a97-958b-00ada84e768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_datetime = min(dt_datetime_start_dates)\n",
    "print('Min time: ')\n",
    "print(min_datetime)\n",
    "max_datetime = max(dt_datetime_end_dates)\n",
    "print('Max time: ')\n",
    "print(max_datetime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e2bcf-61a4-43ac-9592-265c4697b238",
   "metadata": {},
   "source": [
    "## Set path and file names for indeces, dss names and directory names and write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c833f80b59df8b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T20:35:11.969298Z",
     "start_time": "2024-03-01T20:35:09.051341400Z"
    }
   },
   "outputs": [],
   "source": [
    "gw1dss_df = (pd.DataFrame(gw1dss_names))\n",
    "gw1dss_df.to_csv(GW1DssNamesOutPath)\n",
    "print(GW1DssNamesOutPath)\n",
    "index_df = (pd.DataFrame(gw1dss_names))\n",
    "index_df.to_csv(ScenarioIndicesOutPath)\n",
    "print(ScenarioIndicesOutPath)\n",
    "dir_df = (pd.DataFrame(gw1dss_names))\n",
    "dir_df.to_csv(DssDirsOutPath)\n",
    "print(DssDirsOutPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19277cc0585f1d94",
   "metadata": {},
   "source": [
    "## Read and write variables list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3f15cd87dd616",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:54:08.182311Z",
     "start_time": "2024-04-09T01:54:08.163835Z"
    }
   },
   "outputs": [],
   "source": [
    "# get vars\n",
    "hdr, vars = cu.read_from_excel(VarListPath, VarListTab,VarMin,VarMax,hdr=True)\n",
    "gw1var_df = pd.DataFrame(data=vars, columns=hdr)\n",
    "gw1var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf197511748b99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T20:36:38.557235800Z",
     "start_time": "2024-03-01T20:36:35.270309Z"
    }
   },
   "outputs": [],
   "source": [
    "# write vars\n",
    "gw1var_df.to_csv(VarOutPath)\n",
    "VarOutPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628a28e-9f77-493b-8fa2-653417587890",
   "metadata": {},
   "source": [
    "## Loop on DSS files, extract variables and write to scenario-specific CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302a6de1b9a8a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:53:51.833594Z",
     "start_time": "2024-04-09T01:53:51.498533Z"
    }
   },
   "outputs": [],
   "source": [
    "if ExtractIndividualStudies:\n",
    "    for i in range(len(gw1dss_names)):\n",
    "        gw1dss_name = os.path.join(ScenarioDir, gw1dss_names[i])\n",
    "        datetime_start_date = dt_datetime_start_dates[i]\n",
    "        datetime_end_date = dt_datetime_end_dates[i]\n",
    "        print('\\nReading ' + gw1dss_name + '\\n')   \n",
    "        df = preprocess_GW_data_study_dss(gw1var_df, gw1dss_name, datetime_start_date, datetime_end_date, addSRlevels = AggregateStorageLevels, num_vars = NumSrVars, convertAcFtToTaf = ConvertAcFtToTaf)\n",
    "        file_path = gw1dss_name.replace(ModelSubPath, ExtractionSubPath).replace(\".dss\", \".csv\")\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(df.tail(5))\n",
    "        print('\\nWriting ' + file_path + '\\n')\n",
    "        df.to_csv(file_path, na_rep=\"NaN\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90450152-5ade-4e8d-8829-2746f5612913",
   "metadata": {},
   "source": [
    "## Read all DSS files, combine variables and write to single CSV\n",
    "#### Note: warnings will appear whenever a study length is shorter than the max time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be880735-b04e-47ce-969c-e60b1d6ecc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ExtractGroupedStudies:\n",
    "    df = preprocess_compound_GW_data_dss(gw1var_df, ScenarioDir, gw1dss_names, index_names, min_datetime, max_datetime, addSRlevels = AggregateStorageLevels, num_vars = NumSrVars)\n",
    "    df.replace([Nan1, Nan2], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43409952-ab3d-4d75-8555-1d75ecf7b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ExtractGroupedStudies:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a21684-0557-41e0-b4d2-5ea587fafd5d",
   "metadata": {},
   "source": [
    "## Write the compund dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ed99e-35fb-4008-8692-a032f60e8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe to CSV\n",
    "if ExtractGroupedStudies:\n",
    "    print('Writing ' + DataOutPath)\n",
    "    df.to_csv(DataOutPath, na_rep=\"NaN\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b9a43-3bb2-4d0f-93cd-c2836a9278ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
