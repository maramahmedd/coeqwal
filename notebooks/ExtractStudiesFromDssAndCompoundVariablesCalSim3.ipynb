{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45f814080c0b939",
   "metadata": {},
   "source": [
    "## Switches and flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82e6c6-8783-4c8c-8094-b612c260543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtractIndividualStudies = True\n",
    "ExtractGroupedStudies = True\n",
    "ExtractDemandsDeliveries = True\n",
    "ExtractIndividualInflows = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a9bc43-c6c3-4103-a45d-55b7a2938c13",
   "metadata": {},
   "source": [
    "## Import standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c91bd1a1e8beca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T08:04:38.276992Z",
     "start_time": "2024-07-20T08:04:38.274280Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# append coeqwal packages to path\n",
    "sys.path.append('./coeqwalpackage')\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cqwlutils as cu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9145a-2421-4dd1-a31d-1edb2b5a4f64",
   "metadata": {},
   "source": [
    "## Import custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61561cb3284fbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T20:35:57.550559300Z",
     "start_time": "2024-03-07T20:35:57.462942100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import custom modules - NEED WINDOWS OS (NOTE: I had to run this twice, must check why this happens!)\n",
    "from coeqwalpackage.DataExtraction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a886dad8c6c902",
   "metadata": {},
   "source": [
    "## Define contol file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0f49b-17c9-40f5-8861-5680673a5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "CtrlFile = 'CalSim3DataExtractionInitFile_v4.xlsx'\n",
    "CtrlTab = 'Init'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0070e30e-fec8-4e22-bf9f-bd43e1d4f7a9",
   "metadata": {},
   "source": [
    "## Read from control file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614d95e-3b73-42f9-a330-7750b45b921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DssListFile, DssListTab, DssListPath, DssNamesOutPath, DssIndicesOutPath, DssDirsOutPath, VarListPath, VarListFile, VarListTab, VarOutPath, DataOutPath, ConvertDataOutPath, ExtractionSubPath, ModelSubPath, GroupDataDirPath, ScenarioDir, DssMin, DssMax, DirMin, DirMax, IndexMin, IndexMax, StartMin, StartMax, EndMin, EndMax, VarMin, VarMax = cu.read_init_file(CtrlFile, CtrlTab)\n",
    "ScenarioListFile, ScenarioListTab, ScenarioListPath, DVDssNamesOutPath, SVDssNamesOutPath, ScenarioIndicesOutPath, DssDirsOutPath, VarListPath, VarListFile, VarListTab, VarOutPath, DataOutPath, ConvertDataOutPath, ExtractionSubPath, DemandDeliverySubPath, ModelSubPath, GroupDataDirPath, ScenarioDir, DVDssMin, DVDssMax, SVDssMin, SVDssMax, NameMin, NameMax, DirMin, DirMax, IndexMin, IndexMax, StartMin, StartMax, EndMin, EndMax, VarMin, VarMax, DemandFilePath, DemandFileName, DemandFileTab, DemMin, DemMax, InflowOutSubPath, InflowFilePath, InflowFileName, InflowFileTab, InflowMin, InflowMax = cu.read_init_file(CtrlFile, CtrlTab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2529c38-c663-43ee-811d-415fdd815743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print([DssListFile, DssListTab, DssListPath, DssNamesOutPath, DssIndicesOutPath, DssDirsOutPath, VarListPath, VarListFile, VarListTab, VarOutPath, DataOutPath, ConvertDataOutPath, ExtractionSubPath, ModelSubPath, GroupDataDirPath, ScenarioDir, DssMin, DssMax, DirMin, DirMax, IndexMin, IndexMax, StartMin, StartMax, EndMin, EndMax, VarMin, VarMax])\n",
    "print([ScenarioListFile, ScenarioListTab, ScenarioListPath, DVDssNamesOutPath, SVDssNamesOutPath, ScenarioIndicesOutPath, DssDirsOutPath, VarListPath, VarListFile, VarListTab, VarOutPath, DataOutPath, ConvertDataOutPath, ExtractionSubPath, DemandDeliverySubPath, ModelSubPath, GroupDataDirPath, ScenarioDir, DVDssMin, DVDssMax, SVDssMin, SVDssMax, NameMin, NameMax, DirMin, DirMax, IndexMin, IndexMax, StartMin, StartMax, EndMin, EndMax, VarMin, VarMax, DemandFilePath, DemandFileName, DemandFileTab, DemMin, DemMax, InflowOutSubPath, InflowFilePath, InflowFileName, InflowFileTab, InflowMin, InflowMax])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd54452-9c03-4f71-ba08-06fe3b8ba071",
   "metadata": {},
   "source": [
    "## Check for output directory and create if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168bb493-d379-4c25-a56e-e3da4fab4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if output directory exists\n",
    "if not os.path.exists(GroupDataDirPath):\n",
    "    # print warning\n",
    "    print(\"Warning: directory \" + GroupDataDirPath + \" does not exists and will be created\")\n",
    "    \n",
    "    # Create the directory\n",
    "    os.makedirs(GroupDataDirPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f736a-622a-4ca0-86f7-8979963700bf",
   "metadata": {},
   "source": [
    "## Define Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17492ae9-5a01-4eb2-b6e1-4422fbd39d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values as defined by CalSim3\n",
    "Nan1 = -901\n",
    "Nan2 = -902"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cf686-69bd-4a22-bc35-42769740aae7",
   "metadata": {},
   "source": [
    "## Read indeces, dss names, directory names, start and end dates, time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2a998-acab-49e7-a2bd-25e6336f0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvdsshdr, dvdssname = cu.read_from_excel(ScenarioListPath, ScenarioListTab, DVDssMin, DVDssMax, hdr=True)\n",
    "dvdss_names = []\n",
    "for i in range(len(dvdssname)):\n",
    "    dvdss_names.append(dvdssname[i][0])\n",
    "dvdss_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511228c-0d07-4308-86e7-bc1f9a3f74a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdsshdr, svdssname = cu.read_from_excel(ScenarioListPath, ScenarioListTab, SVDssMin, SVDssMax, hdr=True)\n",
    "svdss_names = []\n",
    "for i in range(len(svdssname)):\n",
    "    svdss_names.append(svdssname[i][0])\n",
    "svdss_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903558b7-1a87-4911-ba9a-2f7ac847da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexhdr, index_name = cu.read_from_excel(ScenarioListPath, ScenarioListTab, IndexMin, IndexMax, hdr=True)\n",
    "index_names = []\n",
    "for i in range(len(index_name)):\n",
    "    index_names.append(index_name[i][0])\n",
    "index_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c26379-84b3-425a-a65e-2b6e6852e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyhdr, study_name = cu.read_from_excel(ScenarioListPath, ScenarioListTab, NameMin, NameMax, hdr=True)\n",
    "study_names = []\n",
    "for i in range(len(study_name)):\n",
    "    study_names.append(study_name[i][0])\n",
    "study_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0c016-d82e-4927-b944-f09db7b2f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirhdr, dir_name = cu.read_from_excel(ScenarioListPath, ScenarioListTab, DirMin, DirMax, hdr=True)\n",
    "dir_names = []\n",
    "for i in range(len(dir_name)):\n",
    "    dir_names.append(dir_name[i][0])\n",
    "dir_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456c0e6-61d8-427b-8d45-1814053c4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "starthdr, start_date = cu.read_from_excel(ScenarioListPath, ScenarioListTab, StartMin, StartMax, hdr=True)\n",
    "start_dates = []\n",
    "for i in range(len(start_date)):\n",
    "    start_dates.append(start_date[i][0])\n",
    "#print(start_dates)\n",
    "datetime_start_dates = pd.to_datetime(start_dates)\n",
    "#print(datetime_start_dates)\n",
    "# turns out that dss reading library wands a dt datetime, not pd datetime\n",
    "dt_datetime_start_dates = [dt.to_pydatetime() for dt in datetime_start_dates]\n",
    "#print(dt_datetime_start_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a887b-829e-4773-bb8c-60e8d6ff35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "endhdr, end_date = cu.read_from_excel(ScenarioListPath, ScenarioListTab, EndMin, EndMax, hdr=True)\n",
    "end_dates = []\n",
    "for i in range(len(end_date)):\n",
    "    end_dates.append(end_date[i][0])\n",
    "#print(end_dates)\n",
    "datetime_end_dates = pd.to_datetime(end_dates)\n",
    "#print(datetime_end_dates)\n",
    "dt_datetime_end_dates = [dt.to_pydatetime() for dt in datetime_end_dates]\n",
    "#print(dt_datetime_end_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b72d5a-0f63-4a97-958b-00ada84e768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_datetime = min(dt_datetime_start_dates)\n",
    "print('Min time: ')\n",
    "print(min_datetime)\n",
    "max_datetime = max(dt_datetime_end_dates)\n",
    "print('Max time: ')\n",
    "print(max_datetime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e2bcf-61a4-43ac-9592-265c4697b238",
   "metadata": {},
   "source": [
    "## Set path and file names for indeces, dss names and directory names and write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c833f80b59df8b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T20:35:11.969298Z",
     "start_time": "2024-03-01T20:35:09.051341400Z"
    }
   },
   "outputs": [],
   "source": [
    "dss_df = (pd.DataFrame(dvdss_names))\n",
    "dss_df.to_csv(DVDssNamesOutPath)\n",
    "print(DVDssNamesOutPath)\n",
    "index_df = (pd.DataFrame(dvdss_names))\n",
    "index_df.to_csv(ScenarioIndicesOutPath)\n",
    "print(ScenarioIndicesOutPath)\n",
    "dir_df = (pd.DataFrame(dvdss_names))\n",
    "dir_df.to_csv(DssDirsOutPath)\n",
    "print(DssDirsOutPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19277cc0585f1d94",
   "metadata": {},
   "source": [
    "## Read and write variables list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3f15cd87dd616",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:54:08.182311Z",
     "start_time": "2024-04-09T01:54:08.163835Z"
    }
   },
   "outputs": [],
   "source": [
    "# get vars\n",
    "hdr, vars = cu.read_from_excel(VarListPath, VarListTab,VarMin,VarMax,hdr=True)\n",
    "var_df = pd.DataFrame(data=vars, columns=hdr)\n",
    "var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf197511748b99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T20:36:38.557235800Z",
     "start_time": "2024-03-01T20:36:35.270309Z"
    }
   },
   "outputs": [],
   "source": [
    "# write vars\n",
    "var_df.to_csv(VarOutPath)\n",
    "VarOutPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea322ff-95ab-4985-bb1d-96cd7a887b5e",
   "metadata": {},
   "source": [
    "## Loop on SV DSS files, extract inflow variables and write to scenario-specific CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61ba62-3252-455e-9bed-9c468f736e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vars\n",
    "hdr, vars = cu.read_from_excel(InflowFilePath, InflowFileTab,InflowMin,InflowMax,hdr=True)\n",
    "inflow_var_df = pd.DataFrame(data=vars, columns=hdr)\n",
    "\n",
    "inflow_var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef566e-56f4-4c76-aa6e-6084a7645d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ExtractIndividualInflows:\n",
    "    for i in range(len(svdss_names)):\n",
    "        svdss_name = os.path.join(ScenarioDir, svdss_names[i])\n",
    "        svdss_file = os.path.basename(svdss_name)\n",
    "        dvdss_name = os.path.join(ScenarioDir, dvdss_names[i])\n",
    "        dvdss_file = os.path.basename(dvdss_name)\n",
    "        datetime_start_date = dt_datetime_start_dates[i]\n",
    "        datetime_end_date = dt_datetime_end_dates[i]\n",
    "        print('\\nReading ' + svdss_name + '\\n')   \n",
    "        df = preprocess_study_dss(inflow_var_df, svdss_name, datetime_start_date, datetime_end_date,\n",
    "                                        addsl=False, addres = False, addpump = False, adddelcvp = False, \n",
    "                                        adddelcvpag = False, addcvpscex = False, addcvpprf = False, \n",
    "                                        adddelcvpswp = False, add_nod_storage = False, add_sod_storage = False, \n",
    "                                        add_del_nod_ag = False, add_del_nod_mi = False, add_del_sod_mi = False, \n",
    "                                        add_del_sod_ag = False, add_total_exports = False, \n",
    "                                        add_del_swp_total = False, add_awoann_xa = False)\n",
    "        file_path = dvdss_name.replace(ModelSubPath, InflowOutSubPath).replace(dvdss_file, svdss_file).replace(\".dss\", \"_inflows.csv\")\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        #print(df.tail(5))\n",
    "        print('\\nWriting ' + file_path + '\\n')\n",
    "        df.to_csv(file_path, na_rep=\"NaN\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628a28e-9f77-493b-8fa2-653417587890",
   "metadata": {},
   "source": [
    "## Loop on DSS files, extract variables and write to scenario-specific CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302a6de1b9a8a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:53:51.833594Z",
     "start_time": "2024-04-09T01:53:51.498533Z"
    }
   },
   "outputs": [],
   "source": [
    "if ExtractIndividualStudies:\n",
    "    for i in range(len(dvdss_names)):\n",
    "        dvdss_name = os.path.join(ScenarioDir, dvdss_names[i])\n",
    "        datetime_start_date = dt_datetime_start_dates[i]\n",
    "        datetime_end_date = dt_datetime_end_dates[i]\n",
    "        print('\\nReading ' + dvdss_name + '\\n')   \n",
    "        df = preprocess_study_dss(var_df, dvdss_name, datetime_start_date, datetime_end_date)\n",
    "        file_path = dvdss_name.replace(ModelSubPath, ExtractionSubPath).replace(\".dss\", \".csv\")\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(df.tail(5))\n",
    "        print('\\nWriting ' + file_path + '\\n')\n",
    "        df.to_csv(file_path, na_rep=\"NaN\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90450152-5ade-4e8d-8829-2746f5612913",
   "metadata": {},
   "source": [
    "## Read all DSS files, combine variables and write to single CSV\n",
    "#### Note: warnings will appear whenever a study length is shorter than the max time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be880735-b04e-47ce-969c-e60b1d6ecc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ExtractGroupedStudies:\n",
    "    df = preprocess_compound_data_dss(var_df, ScenarioDir, dvdss_names, index_names, min_datetime, max_datetime)\n",
    "    df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e6c08-3bc4-4cfb-9073-2cc60932298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the two DSS NaN values with NaN\n",
    "if ExtractGroupedStudies:\n",
    "    df.replace([Nan1, Nan2], np.nan, inplace=True)\n",
    "    df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a21684-0557-41e0-b4d2-5ea587fafd5d",
   "metadata": {},
   "source": [
    "## Write the compund dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ed99e-35fb-4008-8692-a032f60e8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe to CSV\n",
    "if ExtractGroupedStudies:\n",
    "    print('Writing ' + DataOutPath)\n",
    "    df.to_csv(DataOutPath, na_rep=\"NaN\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814eeade-5206-4bce-8e02-aee3994e47e6",
   "metadata": {},
   "source": [
    "## Demands and deliveries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30338b68-52fb-4ebb-9f09-c4dbd2198682",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ExtractDemandsDeliveries:\n",
    "    for i in range(len(svdss_names)):\n",
    "        datetime_start_date = dt_datetime_start_dates[i]\n",
    "        datetime_end_date = dt_datetime_end_dates[i]\n",
    "        dvdss_name = os.path.join(ScenarioDir, dvdss_names[i])\n",
    "        svdss_name = os.path.join(ScenarioDir, svdss_names[i])\n",
    "        study_name = study_names[i]\n",
    "        dir_name = dir_names[i]\n",
    "        print('\\nGetting demands and deliveries for ' + dir_name + ' from ' + dvdss_name + ' and ' + svdss_name + '\\n')   \n",
    "        dem_df, del_df, annual_dem_df, annual_del_df, mean_annual_dem, mean_annual_del = preprocess_demands_deliveries(DemandFilePath, DemandFileTab, DemMin, DemMax, study_name, dvdss_name, svdss_name, datetime_start_date, datetime_end_date)\n",
    "        # print(annual_dem_df.tail(5))\n",
    "        # print(annual_del_df.tail(5))\n",
    "        demdel_file_path = os.path.dirname(dvdss_name.replace(ModelSubPath, DemandDeliverySubPath))\n",
    "        print(demdel_file_path)\n",
    "        os.makedirs(demdel_file_path, exist_ok=True)\n",
    "        dem_file_path = os.path.join(demdel_file_path, dir_name + '_DEMANDS.csv')\n",
    "        del_file_path = os.path.join(demdel_file_path, dir_name + '_DELIVERIES.csv')\n",
    "        ann_dem_file_path = os.path.join(demdel_file_path, dir_name + '_DEMANDS-ANNUAL.csv')\n",
    "        ann_del_file_path = os.path.join(demdel_file_path, dir_name + '_DELIVERIES-ANNUAL.csv')\n",
    "        demmean_file_path = os.path.join(demdel_file_path, dir_name + '_DEMANDS-ANNUAL-MEAN.csv')\n",
    "        delmean_file_path = os.path.join(demdel_file_path, dir_name + '_DELIVERIES-ANNUAL-MEAN.csv')\n",
    "        print('Writing ' + dem_file_path)\n",
    "        dem_df.to_csv(dem_file_path, header=True) # write out monthly totals to csv file\n",
    "        print('Writing ' + del_file_path)\n",
    "        del_df.to_csv(del_file_path, header=True) # write out monthly totals to csv file\n",
    "        print('Writing ' + ann_dem_file_path)\n",
    "        annual_dem_df.to_csv(ann_dem_file_path, header=True) # write out annual totals to csv file\n",
    "        print('Writing ' + ann_del_file_path)\n",
    "        annual_del_df.to_csv(ann_del_file_path, header=True) # write out annual totals to csv file\n",
    "        print('Writing ' + demmean_file_path)\n",
    "        mean_annual_dem.to_csv(demmean_file_path, header=True) # writes out a \"mean of all years\" file\n",
    "        print('Writing ' + delmean_file_path)\n",
    "        mean_annual_del.to_csv(delmean_file_path, header=True) # writes out a \"mean of all years\" file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b9a43-3bb2-4d0f-93cd-c2836a9278ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877aa32c-9b7e-40ed-809d-cf5925b52998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
